{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel_argmax(argmax, shape):\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        output_list = []\n",
    "        output_list.append(argmax // (shape[2] * shape[3]))\n",
    "        output_list.append(argmax % (shape[2] * shape[3]) // shape[3])\n",
    "    return tf.stack(output_list)\n",
    "\n",
    "def unpool_layer2x2_batch(x, argmax, offset = 0):\n",
    "    '''\n",
    "    Args:\n",
    "        x: 4D tensor of shape [batch_size x height x width x channels]\n",
    "        argmax: A Tensor of type Targmax. 4-D. The flattened indices of the max\n",
    "        values chosen for each output.\n",
    "    Return:\n",
    "        4D output tensor of shape [batch_size x 2*height x 2*width x channels]\n",
    "    '''\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        x_shape = tf.shape(x)\n",
    "        out_shape = [x_shape[0], x_shape[1]*2 + offset, x_shape[2]*2, x_shape[3]]\n",
    "\n",
    "        batch_size = out_shape[0]\n",
    "        height = out_shape[1]\n",
    "        width = out_shape[2]\n",
    "        channels = out_shape[3]\n",
    "\n",
    "        argmax_shape = tf.to_int64([batch_size, height, width, channels])\n",
    "        argmax = unravel_argmax(argmax, argmax_shape)\n",
    "\n",
    "        t1 = tf.to_int64(tf.range(channels))\n",
    "        t1 = tf.tile(t1, [batch_size*(width//2)*(height//2)])\n",
    "        t1 = tf.reshape(t1, [-1, channels])\n",
    "        t1 = tf.transpose(t1, perm=[1, 0])\n",
    "        t1 = tf.reshape(t1, [channels, batch_size, height//2, width//2, 1])\n",
    "        t1 = tf.transpose(t1, perm=[1, 0, 2, 3, 4])\n",
    "\n",
    "        t2 = tf.to_int64(tf.range(batch_size))\n",
    "        t2 = tf.tile(t2, [channels*(width//2)*(height//2)])\n",
    "        t2 = tf.reshape(t2, [-1, batch_size])\n",
    "        t2 = tf.transpose(t2, perm=[1, 0])\n",
    "        t2 = tf.reshape(t2, [batch_size, channels, height//2, width//2, 1])\n",
    "        \n",
    "        t3 = tf.transpose(argmax, perm=[1, 4, 2, 3, 0])\n",
    "\n",
    "        t = tf.concat([t2, t3, t1], 4)\n",
    "        indices = tf.reshape(t, [(height//2)*(width//2)*channels*batch_size, 4])\n",
    "\n",
    "        x1 = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "        values = tf.reshape(x1, [-1])\n",
    "\n",
    "        delta = tf.SparseTensor(indices, values, tf.to_int64(out_shape))\n",
    "    return tf.sparse_tensor_to_dense(tf.sparse_reorder(delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_minibatch(full_path_unlabeled_files, full_path_labeled_files, k, minibatch_size):\n",
    "\n",
    "    num_files = len(full_path_labeled_files)\n",
    "    \n",
    "    if (k + 1)*minibatch_size > num_files:\n",
    "        num_files_to_load = num_files - k*minibatch_size\n",
    "    else:\n",
    "        num_files_to_load = minibatch_size\n",
    "                             \n",
    "    # Allocate array for unlabeled minibatch images\n",
    "    minibatch_X = np.empty([num_files_to_load, 360, 480, 3], dtype = 'uint8')\n",
    "\n",
    "    # Allocate array for labeled minibatch images\n",
    "    minibatch_Y = np.empty([num_files_to_load, 360, 480], dtype = 'uint8')\n",
    "    \n",
    "    i = 0\n",
    "    for n in range(k*minibatch_size, k*minibatch_size + num_files_to_load):\n",
    "        minibatch_X[i] = cv2.imread(full_path_unlabeled_files[n], 1)\n",
    "        minibatch_Y[i] = cv2.imread(full_path_labeled_files[n], 0)\n",
    "        i = i + 1\n",
    "\n",
    "    # Preprocess unlabeled images\n",
    "    minibatch_X = minibatch_X.astype('float32')\n",
    "    processed_minibatch_X = imagenet_utils.preprocess_input(minibatch_X)\n",
    "\n",
    "    # Preprocess labeled images\n",
    "    processed_minibatch_Y = np_utils.to_categorical(minibatch_Y.flatten(), 12)\n",
    "    processed_minibatch_Y = processed_minibatch_Y.reshape((num_files_to_load, 360*480, 12))\n",
    "\n",
    "    return processed_minibatch_X, processed_minibatch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(unlabeled_path, labeled_path):\n",
    "    \n",
    "    labeled_files = [f for f in listdir(labeled_path) if isfile(join(labeled_path,f))]\n",
    "    unlabeled_files = [f for f in listdir(unlabeled_path) if isfile(join(unlabeled_path,f))]\n",
    "\n",
    "    num_files = len(labeled_files)\n",
    "    \n",
    "    assert (num_files == len(unlabeled_files)), \"Different number of unlabeled and labeled files.\"\n",
    "        \n",
    "    # Shuffle\n",
    "    permutation = list(np.random.permutation(num_files))\n",
    "    \n",
    "    full_path_labeled_files = []\n",
    "    full_path_unlabeled_files = []\n",
    "    \n",
    "    for n in range(0, num_files):\n",
    "        full_path_labeled_files.append(join(labeled_path, labeled_files[permutation[n]]))\n",
    "        full_path_unlabeled_files.append(join(unlabeled_path, unlabeled_files[permutation[n]]))\n",
    "        \n",
    "\n",
    "    return full_path_unlabeled_files, full_path_labeled_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y): \n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_H0*n_W0, n_y])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [3, 3, 3, 64] Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "                        W2 : [3, 3, 64, 128]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [3, 3, 3, 64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [3, 3, 64, 64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W3 = tf.get_variable(\"W3\", [3, 3, 64, 128], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W4 = tf.get_variable(\"W4\", [3, 3, 128, 128], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W5 = tf.get_variable(\"W5\", [3, 3, 128, 256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W6 = tf.get_variable(\"W6\", [3, 3, 256, 256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W7 = tf.get_variable(\"W7\", [3, 3, 256, 256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W8 = tf.get_variable(\"W8\", [3, 3, 256, 512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W9 = tf.get_variable(\"W9\", [3, 3, 512, 512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W10 = tf.get_variable(\"W10\", [3, 3, 512, 512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    \n",
    "    W11 = tf.get_variable(\"W11\", [3, 3, 512, 512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W12 = tf.get_variable(\"W12\", [3, 3, 512, 512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W13 = tf.get_variable(\"W13\", [3, 3, 512, 256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W14 = tf.get_variable(\"W14\", [3, 3, 256, 256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W15 = tf.get_variable(\"W15\", [3, 3, 256, 256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W16 = tf.get_variable(\"W16\", [3, 3, 256, 128], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W17 = tf.get_variable(\"W17\", [3, 3, 128, 128], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W18 = tf.get_variable(\"W18\", [3, 3, 128,  64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W19 = tf.get_variable(\"W19\", [3, 3, 64, 64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W20 = tf.get_variable(\"W20\", [3, 3, 64, 12], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3,\n",
    "                  \"W4\": W4,\n",
    "                  \"W5\": W5,\n",
    "                  \"W6\": W6,\n",
    "                  \"W7\": W7,\n",
    "                  \"W8\": W8,\n",
    "                  \"W9\": W9,\n",
    "                  \"W10\": W10,\n",
    "                  \"W11\": W11,\n",
    "                  \"W12\": W12,\n",
    "                  \"W13\": W13,\n",
    "                  \"W14\": W14,\n",
    "                  \"W15\": W15,\n",
    "                  \"W16\": W16,\n",
    "                  \"W17\": W17,\n",
    "                  \"W18\": W18,\n",
    "                  \"W19\": W19,\n",
    "                  \"W20\": W20}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last unit\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        # Retrieve the parameters from the dictionary \"parameters\" \n",
    "        W1 = parameters['W1']\n",
    "        W2 = parameters['W2']\n",
    "        W3 = parameters['W3']\n",
    "        W4 = parameters['W4']\n",
    "        W5 = parameters['W5']\n",
    "        W6 = parameters['W6']\n",
    "        W7 = parameters['W7']\n",
    "        W8 = parameters['W8']\n",
    "        W9 = parameters['W9']\n",
    "        W10 = parameters['W10']\n",
    "        W11 = parameters['W11']\n",
    "        W12 = parameters['W12']\n",
    "        W13 = parameters['W13']\n",
    "        W14 = parameters['W14']\n",
    "        W15 = parameters['W15']\n",
    "        W16 = parameters['W16']\n",
    "        W17 = parameters['W17']\n",
    "        W18 = parameters['W18']\n",
    "        W19 = parameters['W19']\n",
    "        W20 = parameters['W20']\n",
    "\n",
    "        # Encoder 1\n",
    "        X = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)  \n",
    "\n",
    "        X = tf.nn.conv2d(X, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "        shape_decoder_4 = tf.shape(X)\n",
    "        X, ind1 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "\n",
    "        # Encoder 2\n",
    "        X = tf.nn.conv2d(X, W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "\n",
    "        X = tf.nn.conv2d(X, W4, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "        shape_decoder_3 = tf.shape(X)\n",
    "        X, ind2 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "\n",
    "        # Encoder 3\n",
    "        X = tf.nn.conv2d(X, W5, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W6, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W7, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "        shape_decoder_2 = tf.shape(X)\n",
    "        X, ind3 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "\n",
    "        # Encoder 4\n",
    "        X = tf.nn.conv2d(X, W8, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W9, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "\n",
    "        X = tf.nn.conv2d(X, W10, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "        shape_decoder_1 = tf.shape(X)\n",
    "        X, ind4 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "\n",
    "        # Decoder 1\n",
    "        X = unpool_layer2x2_batch(X, ind4, 1)\n",
    "        X = tf.nn.conv2d(X, W11, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W12, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "\n",
    "        X = tf.nn.conv2d(X, W13, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X)\n",
    "\n",
    "        # Decoder 2\n",
    "        X = unpool_layer2x2_batch(X, ind3)\n",
    "        X = tf.nn.conv2d(X, W14, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W15, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W16, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        # Decoder 3\n",
    "        X = unpool_layer2x2_batch(X, ind2)\n",
    "        X = tf.nn.conv2d(X, W17, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W18, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        # Decoder 4\n",
    "        X = unpool_layer2x2_batch(X, ind1)\n",
    "        X = tf.nn.conv2d(X, W19, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.relu(X) \n",
    "\n",
    "        X = tf.nn.conv2d(X, W20, strides = [1,1,1,1], padding = 'SAME')\n",
    "        X = tf.contrib.layers.batch_norm(X)\n",
    "        X = tf.nn.softmax(X) \n",
    "\n",
    "        X = tf.reshape(X, [tf.shape(X)[0], 360*480, 12])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"  \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train_filelist, Y_train_filelist, learning_rate = 0.009,\n",
    "              epochs = 100, minibatch_size = 64, print_cost = True, option = 'scratch'):\n",
    "\n",
    "    ops.reset_default_graph() # to be able to rerun the model without overwriting tf variables\n",
    "    num_of_classes = 12\n",
    "    (m, n_H0, n_W0, n_C0) = [len(X_train_filelist), 360, 480, 3]\n",
    "    costs = []\n",
    "    epoch_accuracy_list = []\n",
    "    iteration_accuracy_list = []\n",
    "\n",
    "    ##### Operations concerning minibatch size \n",
    "\n",
    "    all_minibatch_sizes = []\n",
    "\n",
    "    num_minibatches = int(m / minibatch_size) \n",
    "    total_num_minibatches = int(math.ceil(m / minibatch_size))\n",
    "    total_iters = total_num_minibatches * epochs\n",
    "\n",
    "    for n in range(0, num_minibatches):\n",
    "        all_minibatch_sizes.append(minibatch_size)\n",
    "\n",
    "    if num_minibatches != total_num_minibatches:\n",
    "        all_minibatch_sizes.append(m - (num_minibatches*minibatch_size))\n",
    "\n",
    "    #####\n",
    "\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, num_of_classes)\n",
    "\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "\n",
    "    # Backpropagation: Define the tensorflow optimizer. SGD\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate, momentum = 0.9).minimize(cost)\n",
    "\n",
    "    # Calculate the correct predictions\n",
    "    predict_op = tf.argmax(Z3, axis = 2)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, axis = 2))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Save model\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Pretrained weights\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W5 = parameters['W5']\n",
    "    W6 = parameters['W6']\n",
    "    W7 = parameters['W7']\n",
    "    W8 = parameters['W8']\n",
    "    W9 = parameters['W9']\n",
    "    W10 = parameters['W10']\n",
    "    \n",
    "    pretrained_variables_dict = {\"vgg_16/conv1/conv1_1/weights\": W1,\n",
    "                  \"vgg_16/conv1/conv1_2/weights\": W2,\n",
    "                  \"vgg_16/conv2/conv2_1/weights\": W3,\n",
    "                  \"vgg_16/conv2/conv2_2/weights\": W4,\n",
    "                  \"vgg_16/conv3/conv3_1/weights\": W5,\n",
    "                  \"vgg_16/conv3/conv3_2/weights\": W6,\n",
    "                  \"vgg_16/conv3/conv3_3/weights\": W7,\n",
    "                  \"vgg_16/conv4/conv4_1/weights\": W8,\n",
    "                  \"vgg_16/conv4/conv4_2/weights\": W9,\n",
    "                  \"vgg_16/conv4/conv4_3/weights\": W10}\n",
    "\n",
    "    pretrained_saver = tf.train.Saver(pretrained_variables_dict)\n",
    "    \n",
    "\n",
    "        # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        if option == 'checkpoint':\n",
    "            saver.restore(sess, \"my_model.ckpt\")\n",
    "        elif option == 'pretrained':\n",
    "            sess.run(init)\n",
    "            pretrained_saver.restore(sess, \"vgg_16.ckpt\")\n",
    "            Z3 = forward_propagation(X, parameters)\n",
    "        else:\n",
    "            sess.run(init)\n",
    "            \n",
    "        # Do the training loop\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            print(\"Epoch %i started.\" % (epoch))\n",
    "\n",
    "            for k in range(0,total_num_minibatches):\n",
    "\n",
    "                # Load a minibatch\n",
    "                minibatch_X, minibatch_Y = load_minibatch(X_train_filelist, Y_train_filelist, k, minibatch_size)\n",
    "\n",
    "                # Run the session to execute the optimizer and the cost.\n",
    "                with tf.device('/device:GPU:0'):\n",
    "                    _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                iteration_accuracy_list.append(accuracy.eval({X: minibatch_X, Y: minibatch_Y}))\n",
    "\n",
    "                # Print training progress\n",
    "                \n",
    "                completed_iters = epoch * total_num_minibatches + (k + 1)\n",
    "                percent_complete = (completed_iters * 100) / total_iters\n",
    "                sys.stdout.write(str(percent_complete)+'%\\r')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "\n",
    "            epoch_accuracy = (sum([x*y for x,y in zip(iteration_accuracy_list, all_minibatch_sizes)]))/sum(all_minibatch_sizes)\n",
    "            iteration_accuracy_list = []\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Epoch %i finished. Cost: %f   Accuracy: %f    Total progress: %f%%\" % (epoch, minibatch_cost, epoch_accuracy, (epoch + 1)*100/epochs))\n",
    "\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "                epoch_accuracy_list.append(epoch_accuracy)\n",
    "\n",
    "            # Save model\n",
    "            saver.save(sess, './my_model.ckpt')\n",
    "\n",
    "        # Plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('Iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # Calculate final accuracy\n",
    "        final_accuracy = sum(epoch_accuracy_list)/epochs\n",
    "        print(\"Final Accuracy:\", final_accuracy)\n",
    "\n",
    "    return X, Y, final_accuracy, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(labeled_path, unlabeled_path):\n",
    "\n",
    "\t# Find labeled files\n",
    "\tlabeled_files = [f for f in listdir(labeled_path) if isfile(join(labeled_path,f))]\n",
    "\t# Find unlabeled files\n",
    "\tunlabeled_files = [f for f in listdir(unlabeled_path) if isfile(join(unlabeled_path,f))]\n",
    "\n",
    "\t# Allocate array for labeled images\n",
    "\timages_labeled = np.empty([len(labeled_files), 360, 480], dtype = 'uint8')\n",
    "\n",
    "\t# Allocate array for unlabeled images\n",
    "\timages_unlabeled = np.empty([len(unlabeled_files), 360, 480, 3], dtype = 'uint8')\n",
    "\n",
    "\n",
    "\t# Reading labeled images\n",
    "\tfor n in range(0, len(labeled_files)):\n",
    "\t    images_labeled[n] = cv2.imread(join(labeled_path,labeled_files[n]), 0)\n",
    "\n",
    "\t# Reading unlabeled images\n",
    "\tfor n in range(0, len(unlabeled_files)):\n",
    "\t    images_unlabeled[n] = cv2.imread(join(unlabeled_path,unlabeled_files[n]), 1)\n",
    "\n",
    "\t# Preprocess unlabeled images\n",
    "\timages_unlabeled = images_unlabeled.astype('float32')\n",
    "\tX = imagenet_utils.preprocess_input(images_unlabeled)\n",
    "\n",
    "\t# Preprocess labeled images\n",
    "\tn_labeled = len(labeled_files)\n",
    "\tY = np_utils.to_categorical(images_labeled.flatten(), 12)\n",
    "\tY = Y.reshape((n_labeled, images_labeled.size / n_labeled, 12))\n",
    "\n",
    "\treturn X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X_test, Y_test):\n",
    "    ops.reset_default_graph()\n",
    "    num_of_classes = 12\n",
    "    (m, n_H0, n_W0, n_C0) = [X_test.shape[0], 360, 480, 3]\n",
    "    parameters = initialize_parameters()\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W5 = parameters['W5']\n",
    "    W6 = parameters['W6']\n",
    "    W7 = parameters['W7']\n",
    "    W8 = parameters['W8']\n",
    "    W9 = parameters['W9']\n",
    "    W10 = parameters['W10']\n",
    "    pretrained_saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "            X, Y = create_placeholders(n_H0, n_W0, n_C0, num_of_classes)\n",
    "            pretrained_saver.restore(sess, \"my_model.ckpt\")\n",
    "            Z3 = forward_propagation(X, parameters)\n",
    "            predict_op = tf.round(Z3)\n",
    "            correct_prediction = tf.equal(predict_op, Y)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            \n",
    "            meanIoU, confusionMatrix = tf.metrics.mean_iou(Y, correct_prediction, num_of_classes)\n",
    "            \n",
    "            init = tf.local_variables_initializer()\n",
    "            sess.run(init)\n",
    "            \n",
    "            for i in range(1000):\n",
    "                iou, _=sess.run([meanIoU, confusionMatrix])\n",
    "            \n",
    "            test_accuracy = accuracy.eval({X: X_test, Y: Y_test}) # regular\n",
    "    return test_accuracy, iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_labeled_path = './CamVid/trainannot'\n",
    "train_unlabeled_path = './CamVid/train'\n",
    "test_labeled_path = './CamVid/testannot'\n",
    "test_unlabeled_path = './CamVid/test'\n",
    "\n",
    "# Define some parameters\n",
    "input_shape = (360, 480, 3)\n",
    "minibatch_size = 5\n",
    "epochs = 1\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing training dataset\n",
      "Listed\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Listing training dataset\")\n",
    "X_train_filelist, Y_train_filelist = list_files(train_unlabeled_path, train_labeled_path)\n",
    "print(\"Listed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:GPU:0\"](Relu_1)]]\n\nCaused by op 'MaxPoolWithArgmax', defined at:\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    self._closing = True\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    _state.contexts = cap_contexts[0]\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    _state.contexts = cap_contexts[0]\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-29295086a3dc>\", line 2, in <module>\n    X, Y, accuracy, parameters = model(X_train_filelist, Y_train_filelist, learning_rate, epochs, minibatch_size, option = 'checkpoint')\n  File \"<ipython-input-18-8031fd4b5ad3>\", line 31, in model\n    Z3 = forward_propagation(X, parameters)\n  File \"<ipython-input-24-73adc1105c5e>\", line 44, in forward_propagation\n    X, ind1 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1810, in max_pool_with_argmax\n    Targmax=Targmax, name=name)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:GPU:0\"](Relu_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1066\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:GPU:0\"](Relu_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-29295086a3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model with pretrained weights from VGG-16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_filelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_filelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-8031fd4b5ad3>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train_filelist, Y_train_filelist, learning_rate, epochs, minibatch_size, print_cost, option)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Run the initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'checkpoint'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"my_model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pretrained'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:GPU:0\"](Relu_1)]]\n\nCaused by op 'MaxPoolWithArgmax', defined at:\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    self._closing = True\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    _state.contexts = cap_contexts[0]\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    _state.contexts = cap_contexts[0]\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-29295086a3dc>\", line 2, in <module>\n    X, Y, accuracy, parameters = model(X_train_filelist, Y_train_filelist, learning_rate, epochs, minibatch_size, option = 'checkpoint')\n  File \"<ipython-input-18-8031fd4b5ad3>\", line 31, in model\n    Z3 = forward_propagation(X, parameters)\n  File \"<ipython-input-24-73adc1105c5e>\", line 44, in forward_propagation\n    X, ind1 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1810, in max_pool_with_argmax\n    Targmax=Targmax, name=name)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/macbookpro13/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:GPU:0\"](Relu_1)]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model with pretrained weights from VGG-16\n",
    "X, Y, accuracy, parameters = model(X_train_filelist, Y_train_filelist, learning_rate, epochs, minibatch_size, option = 'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.\n",
      "Epoch 0 finished. Cost: 2.479584   Accuracy: 0.912702    Total progress: 33.000000%\n",
      "Epoch 1 started.\n",
      "Epoch 1 finished. Cost: 2.457000   Accuracy: 0.913255    Total progress: 66.000000%\n",
      "Epoch 2 started.\n",
      "Epoch 2 finished. Cost: 2.434981   Accuracy: 0.914527    Total progress: 100.000000%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c35e185d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.913494911459\n"
     ]
    }
   ],
   "source": [
    "# Train the model with random initialized weights, dataset is formed by 20 images\n",
    "X, Y, accuracy, parameters = model(X_train_filelist, Y_train_filelist, learning_rate, epochs, minibatch_size, option = 'scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing dataset\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading testing dataset\")\n",
    "X_test, Y_test = load_data(test_labeled_path, test_unlabeled_path)\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'MaxPoolWithArgmax': Could not satisfy explicit device specification '/device:CPU:0' because no supported kernel for CPU devices is available.\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:CPU:0\"](Relu_1)]]\n\nCaused by op u'MaxPoolWithArgmax', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/zaziza/virtualenv/project_space/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-7e435384885a>\", line 1, in <module>\n    test_accuracy, iou = testing(X_test, Y_test)#accuracy.eval({X: X_test, Y: Y_test})\n  File \"<ipython-input-24-3f48d4d4bf7e>\", line 20, in testing\n    Z3 = forward_propagation(X, parameters)\n  File \"<ipython-input-20-edf43b0168ba>\", line 44, in forward_propagation\n    X, ind1 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1898, in max_pool_with_argmax\n    Targmax=Targmax, name=name)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MaxPoolWithArgmax': Could not satisfy explicit device specification '/device:CPU:0' because no supported kernel for CPU devices is available.\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:CPU:0\"](Relu_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7e435384885a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#accuracy.eval({X: X_test, Y: Y_test})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-3f48d4d4bf7e>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(X_test, Y_test)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'MaxPoolWithArgmax': Could not satisfy explicit device specification '/device:CPU:0' because no supported kernel for CPU devices is available.\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:CPU:0\"](Relu_1)]]\n\nCaused by op u'MaxPoolWithArgmax', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/zaziza/virtualenv/project_space/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-7e435384885a>\", line 1, in <module>\n    test_accuracy, iou = testing(X_test, Y_test)#accuracy.eval({X: X_test, Y: Y_test})\n  File \"<ipython-input-24-3f48d4d4bf7e>\", line 20, in testing\n    Z3 = forward_propagation(X, parameters)\n  File \"<ipython-input-20-edf43b0168ba>\", line 44, in forward_propagation\n    X, ind1 = tf.nn.max_pool_with_argmax(X, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1898, in max_pool_with_argmax\n    Targmax=Targmax, name=name)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/zaziza/virtualenv/project_space/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MaxPoolWithArgmax': Could not satisfy explicit device specification '/device:CPU:0' because no supported kernel for CPU devices is available.\n\t [[Node: MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/device:CPU:0\"](Relu_1)]]\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, iou = testing(X_test, Y_test)#accuracy.eval({X: X_test, Y: Y_test})\n",
    "print(test_accuracy)\n",
    "print(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
